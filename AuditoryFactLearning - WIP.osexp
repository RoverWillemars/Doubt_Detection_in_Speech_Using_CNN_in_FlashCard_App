---
API: 3
OpenSesame: 4.0.24
Platform: nt
---
set width 1024
set uniform_coordinates yes
set title "Auditory Fact Learning"
set subject_parity even
set subject_nr 0
set start experiment
set sound_sample_size -16
set sound_freq 48000
set sound_channels 2
set sound_buf_size 1024
set sampler_backend legacy
set round_decimals 2
set mouse_backend legacy
set keyboard_backend legacy
set height 768
set fullscreen no
set form_clicks no
set foreground black
set font_underline no
set font_size 18
set font_italic False
set font_family mono
set font_bold False
set experiment_path "D:\\Studie\\User Modelling\\user-modelling-project-neural-navigators"
set disable_garbage_collection False
set description "The main experiment item"
set coordinates uniform
set compensation 0
set color_backend legacy
set clock_backend legacy
set canvas_backend legacy
set background "#fcf7f0"

define inline_script append_data
	set description "Executes Python code"
	___run__
	# save the data of the first block into a seperate variable for appending later
	dat_b3 = m.export_data(os.path.join(data_folders["trial_info"], f"subj_{var.subject_nr}_block{block_n}.csv"))	
	
	# concatenate data from three blocks
	dat_total = pd.concat([dat_b1, dat_b2, dat_b3], ignore_index=True)
	final_output_path = (os.path.join(data_folders["final_info"], f"subj_{var.subject_nr}_final.csv"))	
	dat_total.to_csv(final_output_path, index=False) 
	__end__
	set _prepare ""

define inline_script block2_setup
	set description "Executes Python code"
	___run__
	var.time_up = False
	var.session_start_time = clock.time()
	
	# save the data of the first block into a seperate variable for appending map
	print(m.get_mastered_facts(clock.time()))
	dat_b1 = m.export_data(os.path.join(data_folders["trial_info"], f"subj_{var.subject_nr}_block{block_n}.csv"))
	
	##### refine model with new data ####
	if var.fine_tune is True:
		# fine-tune model on acquired data from first block
		confident_dir_finetune = data_folders["confident"]
		n_conf = len(os.listdir(confident_dir_finetune))
		doubtful_dir_finetune = data_folders["doubtful"]
		n_doubt = len(os.listdir(doubtful_dir_finetune))
		
		if n_conf > 4 and n_doubt > 4:
			X_fine, y_fine = prepare_dataset(confident_dir_finetune, doubtful_dir_finetune)
		
		    	# Fine-tune on a smaller set of data (this could be a new dataset or a subset of the original)
		    	X_train_fine, X_val_fine, y_train_fine, y_val_fine = train_test_split(X_fine, y_fine, test_size=0.2)  # Example small set
		    	fine_tune_history = fine_tune_model(loaded_model, X_train_fine, y_train_fine, X_val_fine, y_val_fine, fine_tune_epochs=10)
		
		    	# Evaluate the fine-tuned model <-- unless we're going to compare models, this is not necessary I think
		    	evaluate_model(loaded_model, X_val_fine, y_val_fine)
	
	# set image set and system based on experiment_order
	if experiment_order == 0 or experiment_order == 1:
		image_set = 1
		images_dir = os.path.join(var.main_dir, "Images\\Country_Outlines\\set_1")
	elif experiment_order == 2 or experiment_order == 3:
		image_set = 2
		images_dir = os.path.join(var.main_dir, "Images\\Country_Outlines\\set_2")
	     
	if experiment_order == 0 or experiment_order == 2:
		model_type = "Standard"
	elif experiment_order == 1 or experiment_order == 3:
		model_type = "Doubt-Detection"
	    
	var.checkDoubt = False # no longer ask for doubt/confidence after trial
	
	# block number
	block_n = 2
	
	# Check whetther doubt detection should be included in next block
	includeDoubt = False
	if model_type == "Doubt-Detection":
		includeDoubt = True
	
	# initialize new model
	m = SpacingModel(includeDoubt = includeDoubt)
	
	countries = loadImages()
	
	facts = []
	for idx, name in enumerate(countries.keys()):
		facts.append(Fact(idx+1, countries[name], name.lower()))
	
	for fact in facts:
		m.add_fact(fact)
	__end__
	set _prepare ""

define inline_script block3_setup
	set description "Executes Python code"
	___run__
	var.time_up = False
	var.session_start_time = clock.time()
	
	# save the data of the first block into a seperate variable for appending later
	dat_b2 = m.export_data(os.path.join(data_folders["trial_info"], f"subj_{var.subject_nr}_block{block_n}.csv"))	
	
	if experiment_order == 0 or experiment_order == 1:
		image_set = 2
		images_dir = os.path.join(var.main_dir, "Images\\Country_Outlines\\set_2")
	elif experiment_order == 2 or experiment_order == 3:
		image_set = 1
		images_dir = os.path.join(var.main_dir, "Images\\Country_Outlines\\set_1") 
	     
	if experiment_order == 0 or experiment_order == 2:
		model_type = "Doubt-Detection"
	elif experiment_order == 1 or experiment_order == 3:
		model_type = "Standard"
	
	# block number
	block_n = 3
	
	# Check whetther doubt detection should be included in next block
	includeDoubt = False
	if model_type == "Doubt-Detection":
		includeDoubt = True
	
	# initialize new model
	m = SpacingModel(includeDoubt = includeDoubt)
	
	countries = loadImages()
	
	facts = []
	for idx, name in enumerate(countries.keys()):
		facts.append(Fact(idx+1, countries[name], name.lower()))
	
	for fact in facts:
		m.add_fact(fact)
	__end__
	set _prepare ""

define inline_script constants_memoryAlloc_setup
	set description "Executes Python code"
	___run__
	# create folders for organizing doubtful/confident responses
	data_folders = createFolders()
	
	# load CNN
	os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
	model_path = os.path.join(var.main_dir, "cnn_model-best.h5")
	loaded_model = load_model(model_path)
	
	# preallocate confidence_level
	audio_memoryAlloc = os.path.join(var.main_dir, 'speech_recognition', 'audioFile_memoryAllocation', 'memory_allocation.wav') # Provide path to audio file
	confidence_level = predict_confidence(loaded_model, audio_memoryAlloc)
	
	# the files not saved to folder can probably be overwritten all the time right, in that case, I make another variable for the .wav file name
	file_path_overwrite = os.path.join(data_folders["participant_data_dir"], "audio_to_overwrite.wav")
	
	# set stimuli scaling
	stim_scale = 0.35 #stimuli are 280x280 pixels at .4x scale. sreen size is 1024x768
	
	# randomly pick order of stimuli-set and system-type for subject
	# (in total 2*2 unique combinations)
	experiment_order = randrange(0,4)
	
	# block number
	block_n = 1
	
	# stimuli set
	image_set = 0
	
	# standard model 1st block
	model_type = "Standard"
	__end__
	set _prepare ""

define sequence experiment
	set flush_keyboard yes
	set description "Runs a number of items in sequence"
	run loading_packages True
	run learning_session_setup always
	run library_function_setup True
	run constants_memoryAlloc_setup True
	run present_questions True
	run instructions True
	run slimstampen_setup always
	run while_there_is_time_left always
	run firstblockcompleted True
	run block2_setup True
	run while_there_is_time_left True
	run secondblockcompleted True
	run block3_setup True
	run while_there_is_time_left True
	run append_data True
	run experimentcompleted True

define sketchpad experimentcompleted
	set duration keypress
	set description "Displays stimuli"
	draw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=18 html=yes show_if=always text="Experiment completed! <br /><br />Thank you so much for your participation!<br /><br />Press spacebar to close the window" x=0 y=0 z_index=0

define sketchpad firstblockcompleted
	set duration keypress
	set description "Displays stimuli"
	draw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=18 html=yes show_if=always text="First block completed, you can take a short break. <br /><br />Press space when you are ready to continue<br />" x=0 y=0 z_index=0

define sketchpad instructions
	set duration keypress
	set description "Displays stimuli"
	draw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=16 html=yes show_if=always text="Instructions:<br /><br />Your task during this experiment will be learn the outlines of various countries.<br />This can be quite challenging, so don't worry if you get some wrong. <br />However, still try your best!<br /><br />The first time you see a new country outline, the name and<br />how it is pronounced will be played out loud. <br />The rest of the experiment will consist of random countries <br />that will be shown to you and you have to press SPACE to start your response.<br />Say the country name and you get feedback with if you were correct or incorrect. <br /><br />The experiment consists of three blocks.<br /><br />For the first block, after each question, you will be asked whether <br />you were confident in your answer (press A) or doubtful (press L).<br />For the second and third block, you will not be asked this<br /><br />The experiment should take around 30 minutes.<br /><br />Press SPACE when you've understood and are ready to start!" x=0 y=0 z_index=0

define inline_script learning_session_setup
	set description "Executes Python code"
	set _run ""
	___prepare__
	# Main directory, containing all necessary files and folder
	#var.main_dir = "C:\\Users\\Rover\\user-modelling-project-neural-navigators" 
	var.main_dir = "D:\\Studie\\User Modelling\\user-modelling-project-neural-navigators"
	#var.main_dir = "C:\\Users\\remon\\OneDrive\\Bureaublad\\BCN_ReMa2\\User_Modelling\\GitHub"
	#var.main_dir = "C:\\Users\\rlina\\Documents\\Block1\\User modelling\\gitcode\\user-modelling-project-neural-navigators"
	
	# Check each trial manually for doubt
	var.checkDoubt = True
	
	# Maximum time from hitting Space to start of phrase
	var.secToStart = 3
	# Maximum time from start to end of phrase
	var.secToSpeak = 4
	
	# Start the clock
	var.session_start_time = clock.time()
	
	# Session will run until time_up == True
	var.time_up = False
	
	# Keep track of trial number
	var.trial_num = 1
	
	# Settings
	var.block1_duration = 10 * 60000 # 10 minutes
	var.session_duration = 15 * 60000 # 15 minutes
	var.feedback_duration = 800
	var.inter_trial_interval = 200
	
	var.show_demo = True
	var.fine_tune = False # no longer finetune 
	__end__

define inline_script library_function_setup
	set description "Executes Python code"
	set _run ""
	___prepare__
	import os
	import csv
	import librosa
	import numpy as np
	from random import randrange
	import speech_recognition as sr
	import soundfile as sf
	import jellyfish as jf
	import phonetics as ph
	import pyttsx3
	import tensorflow as tf
	from sklearn.model_selection import train_test_split
	from sklearn.metrics import confusion_matrix, classification_report
	
	###########################
	# Functions can be found below
	###########################
	
	# Create folders
	def createFolders():
	    folder_list = {}
	    
	    participant_dir = os.path.join(var.main_dir, "participant_data")
	    folder_list["participant_data_dir"] = participant_dir
	    
	    # Trial info
	    trial_info_dir = os.path.join(var.main_dir, "participant_data", "trial_info")
	    if not os.path.exists(trial_info_dir):
	            os.makedirs(trial_info_dir)
	    folder_list["trial_info"] = trial_info_dir
	    
	    # Final info
	    final_info_dir = os.path.join(trial_info_dir, "final")
	    if not os.path.exists(final_info_dir):
	            os.makedirs(final_info_dir)
	    folder_list["final_info"] = final_info_dir
	    
	    # Confident
	    conf_corr_dir = os.path.join(var.main_dir, "participant_data", f"subj_{var.subject_nr}_rec", "confident") # to ensure finetuning data is from respective participant 
	    if not os.path.exists(conf_corr_dir):
		    os.makedirs(conf_corr_dir)
	    folder_list["confident"] = conf_corr_dir
	    
	    # Doubtful
	    doubt_corr_dir = os.path.join(var.main_dir, "participant_data", f"subj_{var.subject_nr}_rec", "doubtful")
	    if not os.path.exists(doubt_corr_dir):
		    os.makedirs(doubt_corr_dir)
	    folder_list["doubtful"] = doubt_corr_dir
	    return folder_list
	 
	
	
	def doubtPrompt(my_canvas, my_keyboard):
	    # Ask participant if the response was doubtful/confident
	    # Returns True if doubtful, False if confident
	    my_canvas.clear()
	    basicUIfeatures(my_canvas, False)
	    my_canvas.image(prompt, scale=stim_scale, y=-200)
	    my_canvas.text("How confident was your last answer?", y = 0, font_size = 20, color = "black")
	    my_canvas.text("Press \"A\" for confident", y = 50, font_size = 20, color = "black")
	    my_canvas.text("and \"L\" key for doubtful.", y = 100, font_size = 20, color = "black")
	    my_canvas.prepare()
	    my_canvas.show()
			
	    clock.sleep(1500)
		
		# Lock user in this loop till they respond with "space" or "z" key.
	    while True:
		    # Get keypress
		    key, time = my_keyboard.get_key()
				
		    if key == "a":
			    doubt = False
			    break
		    elif key == "l":
			    doubt = True
			    break
		
	    return doubt
	
	# Checks for the phonetic similarity between two phrases
	def checkSimilarity(answer, speech_answer):
	    ph_ans = ph.dmetaphone(answer)
	    ph_speech_ans = ph.dmetaphone(speech_answer)
	    
	    if jf.levenshtein_distance(ph_ans[0], ph_speech_ans[0]) <= 1 \
	            and ph_ans[0] != "" and ph_speech_ans[0] != "":
	        return True
	    if jf.levenshtein_distance(ph_ans[0], ph_speech_ans[1]) <= 1 \
	            and ph_ans[0] != "" and ph_speech_ans[1] != "":
	        return True
	    if jf.levenshtein_distance(ph_ans[1], ph_speech_ans[0]) <= 1 \
	            and ph_ans[1] != "" and ph_speech_ans[0] != "":
	        return True
	    if jf.levenshtein_distance(ph_ans[1], ph_speech_ans[1]) <= 1 \
	            and ph_ans[1] != "" and ph_speech_ans[1] != "":
	        return True
	    
	    return False
	
	def speakPhrase(text):
	    engine = pyttsx3.init("sapi5")
	    engine.setProperty('rate', 140)
	    print()
	    engine.say(text)
	    try:
	        engine.runAndWait()
	    except Exception:
	        pass
	    engine.runAndWait()
	
	def basicUIfeatures(canvas, response_box = True): #280x280 pixels at .4x scale. sreen size is 1024x768
	    canvas['stimulus_box_shadow'] = Rect(x=-147, y=-320, w=300, h=300, color="black", fill=True) #371 & 374
	    canvas['stimulus_box'] = Rect(x=-150, y=-324, w=300, h=300, color="white", fill=True)
	    if response_box == True:
	        canvas['response_box_shadow'] = Rect(x=-149, y=51, w=303, h=53, color="black", fill=True)
	        canvas['response_box'] = Rect(x=-150, y=50, w=300, h=50, color="white", fill=True)
	               
	def askConfidence(canvas):
	    my_canvas.text("How confident was your last answer?", y = 100, font_size = 20, color = "black")
	    
	def splitClasses(audio_data, transcription, sample_type, sample_rate): # sample_type = doubt or confident
	    sf.write(f"{main_dir}\\speech_recognition\\recordingsV2\\{sample_type}\\{transcription}_{sample_type}.wav", audio_data, sample_rate)
	
	###########################
	# CNN Functions can be found below
	###########################
	
	# Extract Mel Spectrograms
	def extract_mel_spectrogram(audio_file, n_mels=128, n_fft=2048, hop_length=512):
	    y, sr = librosa.load(audio_file, sr=None)
	    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)
	    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)
	    return log_spectrogram
	
	# Define pad_spectrogram to pad spectrograms to a consistent length
	def pad_spectrogram(spec, max_len=128):
	    if spec.shape[1] < max_len:
	        pad_width = max_len - spec.shape[1]
	        spec = np.pad(spec, pad_width=((0, 0), (0, pad_width)), mode='constant')
	    else:
	        spec = spec[:, :max_len]
	    return spec
	
	# Prepare the dataset
	def prepare_dataset(confident_dir, doubtful_dir, max_pad_len=128):
	    spectrograms = []
	    labels = []
	    # Process confident files
	    for filename in os.listdir(confident_dir):
	        if filename.endswith('.wav'):
	            file_path = os.path.join(confident_dir, filename)
	            spectrogram = extract_mel_spectrogram(file_path)
	            spectrogram = pad_spectrogram(spectrogram, max_pad_len)
	            spectrograms.append(spectrogram)
	            labels.append(1)  # 1 for confident
	    # Process doubtful files
	    for filename in os.listdir(doubtful_dir):
	        if filename.endswith('.wav'):
	            file_path = os.path.join(doubtful_dir, filename)
	            spectrogram = extract_mel_spectrogram(file_path)
	            spectrogram = pad_spectrogram(spectrogram, max_pad_len)
	            spectrograms.append(spectrogram)
	            labels.append(0)  # 0 for doubtful
	    spectrograms = np.array(spectrograms)
	    labels = np.array(labels)
	    # Reshape the spectrograms for CNN input (Add channel dimension)
	    spectrograms = spectrograms[..., np.newaxis]
	    return spectrograms, labels
	    
	# Step 6: Load a pre-trained model
	def load_model(model_path="cnn_model-best.h5"):
	    loaded_model = tf.keras.models.load_model(model_path)
	    print(f"Model loaded from: {model_path}")
	    return loaded_model
	
	# Step 7: Fine-tune the loaded model on new data
	def fine_tune_model(model, X_train, y_train, X_val, y_val, fine_tune_epochs=10, fine_tune_lr=1e-5):
	    # Compile the model with a lower learning rate
	    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_lr),
	                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])
	    
	    # Fine-tune the model
	    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=fine_tune_epochs)
	    return history
	
	# Classify audio file as confident/doubtful
	def predict_confidence(model, audio_file, max_pad_len=128):
	    spectrogram = extract_mel_spectrogram(audio_file)
	    spectrogram = pad_spectrogram(spectrogram, max_pad_len)
	    spectrogram = np.expand_dims(spectrogram, axis=-1)  # Add channel dimension
	    spectrogram = np.expand_dims(spectrogram, axis=0)    # Add batch dimension
	
	    prediction = model.predict(spectrogram)
	    predicted_class = np.argmax(prediction, axis=1)[0]  # 0 = Doubtful, 1 = Confident
	
	    if predicted_class == 1:
	        return "Confident"
	    else:
	        return "Doubtful"
	
	# Evaluate model on the validation data
	def evaluate_model(model, X_val, y_val):
	    predictions = model.predict(X_val)
	    predicted_classes = np.argmax(predictions, axis=1)
	
	    # Confusion matrix and classification report
	    cm = confusion_matrix(y_val, predicted_classes)
	    cr = classification_report(y_val, predicted_classes, target_names=['Doubtful', 'Confident'])
	
	    print("Confusion Matrix:")
	    print(cm)
	    print("\nClassification Report:")
	    print(cr)
	
	    correct_confident = cm[1, 1]  # True positives (confident correctly classified)
	    correct_doubtful = cm[0, 0]  # True negatives (doubtful correctly classified)
	
	    print(f"\nCorrectly classified Confident samples: {correct_confident}")
	    print(f"Correctly classified Doubtful samples: {correct_doubtful}")
	__end__

define sketchpad loading_packages
	set duration 0
	set description "Displays stimuli"
	draw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=18 html=yes show_if=always text="Welcome! <br /><br />Allocating memory, wait a few seconds please." x=0 y=0 z_index=0

define inline_script present_questions
	set description "Executes Python code"
	___run__
	# had to move this since folder_list is created after prepare phase
	demo_path = os.path.join(data_folders["final_info"], "demo.csv") # instead of var.main_dir
	if not os.path.exists(demo_path):
	    with open(demo_path, 'w', newline='') as file:
	        writer = csv.writer(file)
	        writer.writerow(question_types)
	
	# create canvas
	demo_canvas = Canvas()
	var.q_index = 0
	answer = ""
	answer_list = [var.subject_nr]
	
	while(show_demo == True):
	    
	    demo_canvas.text(list_of_questions[q_index], y=0, font_size=20, color="black")
	    demo_canvas.text("Write you answer and press ENTER to continue.", y=100, font_size=20, color="black")
	    demo_canvas.prepare()
	    demo_canvas.show()
	    
	    demo_keyboard = Keyboard()
	    
	    key_press, time = demo_keyboard.get_key()
	    
	    if key_press == 'backspace' and len(answer) > 0:
	        answer = answer[:-1]
	        demo_canvas.clear()
	        demo_canvas.text(answer, y=200, font_size=20, color="black")
	        demo_canvas.prepare()
	        demo_canvas.show()
	        
	    elif key_press == 'return':
	        # Check for valid answers
	        validAnswer = True
	        if answer == "":
	            # Empty answer
	            validAnswer = False
	        elif q_index == 0 and (not answer.isnumeric() or (answer.isnumeric() and int(answer) < 0)):
	            # Age check (answer is a number greather or equal to 0)
	            validAnswer = False
	        elif q_index == 1 and answer not in ["male", "female", "other"]:
	            # Gender check (answer is a gender option)
	            validAnswer = False
	        elif q_index == 3 and answer not in ["1", "2", "3", "4", "5"]:
	            # Rating check (rating is a number between 1 and 5)
	            validAnswer = False
	        
	        if validAnswer:
	            # Go to next question
	            q_index = q_index + 1
	            
	            # 
	            if q_index >= len(list_of_questions):
	                show_demo = False
	                
	            answer_list.append(answer)
	            answer = ""
	            demo_canvas.clear()
	    
	    elif key_press.isalnum() and key_press != 'backspace':
	        if key_press == "space":
	            key_press = " "
	        answer += key_press
	        demo_canvas.clear()
	        demo_canvas.text(answer, y=200, font_size=20, color="black")
	        demo_canvas.prepare()
	        demo_canvas.show()
	
	# Append to the demo.csv file
	with open(demo_path, 'a', newline='') as file:
	    writer = csv.writer(file)
	    writer.writerow(answer_list)
	__end__
	___prepare__
	question_types = ["subj_nr", "age", "gender", "nationality", "geo_familiarity"]
	list_of_questions=[
	    "What is your age?",
	    "What gender do you identify as?\n(Choose from 'male', 'female' or 'other')",
	    "What nationality are you?",
	    "How familiar are you with geography?\n(Choose from a scale of 1 (not very familiar) to 5 (very familiar))"]
	__end__

define inline_script present_trial
	set description "Executes Python code"
	___run__
	trial_start_time = clock.time()
	
	#data_folders = createFolders() <-- we can set fixed variables like these (or others we want to initialize earlier on) in e.g. learning_session inline script.
	
	# Determine path of recording file
	audio_name = f"subj_{var.subject_nr}_trial_{var.trial_num}.wav"
	
	# Get next fact from the model
	next_fact, new = m.get_next_fact(current_time = trial_start_time)
	prompt = next_fact.question
	answer = next_fact.answer
	
	my_canvas = Canvas()
	
	basicUIfeatures(my_canvas) #defined in 'prepare'
	#Show prompt:
	my_canvas.image(prompt, scale=stim_scale, y=-200)
	if not new:
		my_canvas.text("Press Space to start talking", y=0, font_size=20, color="black")
	if new:
		my_canvas.text("Press Space if you got it", y=0, font_size=20, color="black")
		my_canvas.text(answer, y=70, font_size=20, color="black")
		
	my_canvas.prepare()
	my_canvas.show()
	
	if new:
		# --------------------
		# --- NEW STIMULUS ---
		# --------------------
		
		clock.sleep(200)
		speakPhrase(answer)
		clock.sleep(500)
		
		# Listen for keyboard input
		my_keyboard = Keyboard()
		rt = float("inf")
		
		while True:
			key, time = my_keyboard.get_key()
		
			if key == "space":
				# When the spacebar is pressed,
				# the response time is determined
				rt = clock.time() - trial_start_time
				break
		
		response = Response(next_fact, trial_start_time, rt, True, np.nan, np.nan, np.nan, block_n, image_set, model_type, experiment_order, False) 
			
		m.register_response(response) 
	else:
		# ----------------
		# --- STIMULUS ---
		# ----------------
		
		# Listen for keyboard input
		my_keyboard = Keyboard()
		rt = float("inf")
		
		while True:
			key, time = my_keyboard.get_key()
		
			if key == "space":
				# When the spacebar is pressed,
				# the response time is determined
				rt = clock.time() - trial_start_time
				break
		
		# Record audio
		r = sr.Recognizer()
		with sr.Microphone() as source:
			# r.adjust_for_ambient_noise(source)
			print("Start talking")
		
			# Show that the recording has started
			my_canvas.clear()
			basicUIfeatures(my_canvas)
			my_canvas.image(prompt, scale=stim_scale, y=-200)
			my_canvas.text("Start talking...", y = 0, font_size = 20, color = "green")
			#if new: why is this here?
				#my_canvas.text(answer, y = 30, font_size = 20, color = "black")
			my_canvas.prepare()
			my_canvas.show()
			
			waitedTooLong = False
			try:
				audio = r.listen(source, timeout=var.secToStart, phrase_time_limit=var.secToSpeak)
			except sr.WaitTimeoutError:
				waitedTooLong = True
		
		error = ""
		if waitedTooLong: # need to check whether it should be recorded like this
			error = "Answer took too long"
	
		else:
			# Save audio as wav file (for feature extraction)
			with open(file_path_overwrite, "wb") as f:
				f.write(audio.get_wav_data())
			
			# Perform speech recognition
			print("Speech recognition")
			try:
				speech_response = r.recognize_google(audio).lower()
			except sr.UnknownValueError:
				print("Could not understand audio")
				error = "Could not understand audio"
			except sr.RequestError as e:
				print("Could not request results from Google:" + e)
				error = "Could not request results from Google"
				
		# Check if the response is correct
		if error == "":
			if answer == speech_response:
				correct = True
			else:
				correct = checkSimilarity(answer, speech_response)
		else:
			correct = False
		
		# Show feedback
		feedback_color = "green" if correct else "red"
		if error == "":
			if correct:
				my_canvas.text(speech_response, y = 70, color = feedback_color)
			elif not correct:
				my_canvas.text(speech_response, y = 70, color = feedback_color)
				my_canvas.rect(x=-149, y=97, w=303, h=53, color="black", fill=True)
				my_canvas.rect(x=-150, y=95, w=300, h=50, color="white", fill=True)
				my_canvas.text(answer , y = 120, color = "black")	
		else:
			my_canvas.text(error, y = 70, color = feedback_color)
			my_canvas.rect(x=-149, y=97, w=303, h=53, color="black", fill=True)
			my_canvas.rect(x=-150, y=95, w=300, h=50, color="white", fill=True)
			my_canvas.text(answer , y = 120, color = "black")
			
		my_canvas.prepare()
		my_canvas.show()
		if not correct or (correct and answer != speech_response): # does the second part of the logic even make sense (i.e., will that ever happen?)
			speakPhrase(answer)
		clock.sleep(var.feedback_duration)
		
		if not waitedTooLong:
			# -----------------------
			# - Extracting features -
			# -----------------------
			confidence_level = predict_confidence(loaded_model, file_path_overwrite)
		
		# Show doubt/confident prompt
		if var.checkDoubt:
			doubt = doubtPrompt(my_canvas, my_keyboard)
		
			if not waitedTooLong:
				response = Response(next_fact, trial_start_time, rt, correct, speech_response, doubt, confidence_level, block_n, image_set, model_type, experiment_order, m.get_mastery_of_fact(clock.time(), next_fact))
			elif waitedTooLong:
				response = Response(next_fact, trial_start_time, rt, False, np.nan, np.nan, np.nan, block_n, image_set, model_type, experiment_order, m.get_mastery_of_fact(clock.time(), next_fact))
		
		# if there's no doubt check then
		elif not var.checkDoubt:
			if not waitedTooLong:
				response = Response(next_fact, trial_start_time, rt, correct, speech_response, np.nan, confidence_level, block_n, image_set, model_type, experiment_order, m.get_mastery_of_fact(clock.time(), next_fact))
			elif waitedTooLong:	
				response = Response(next_fact, trial_start_time, rt, False, np.nan, np.nan, np.nan, block_n, image_set, model_type, experiment_order, m.get_mastery_of_fact(clock.time(), next_fact))
		
		# Register response and write to csv 
		m.register_response(response) 	
		dat = m.export_data(os.path.join(data_folders["trial_info"], f"subj_{var.subject_nr}_block{block_n}.csv"))	
		
		# Save to data folders
		if not waitedTooLong and var.checkDoubt:
			if doubt:
				file_path = os.path.join(data_folders["doubtful"], audio_name)
			elif not doubt:
				file_path = os.path.join(data_folders["confident"], audio_name)
			with open(file_path, "wb") as f:
			    f.write(audio.get_wav_data())
		
		# Increment trial number
		var.trial_num += 1
	
	# Clear the screen between trials
	my_canvas.clear()
	my_canvas.prepare()
	my_canvas.show()
	clock.sleep(var.inter_trial_interval)
	
	# Check whether all items have been mastered
	print("Mastery ('" + next_fact.answer + "'): " + str(m.get_mastery_of_fact(clock.time(), next_fact)))
	perc_mastered_items = len(m.get_mastered_facts(clock.time())) / len(m.facts)
	print(perc_mastered_items)
	
	# Check if time is up
	if block_n == 1:
		# First block (training)
		duration = var.block1_duration
	else:
		# Second/third block
		duration = var.session_duration
		
	if perc_mastered_items == 1 or ((clock.time() - var.session_start_time) >= duration):
		var.time_up = True
	__end__
	set _prepare ""

define sketchpad secondblockcompleted
	set duration keypress
	set description "Displays stimuli"
	draw textline center=1 color=black font_bold=no font_family=mono font_italic=no font_size=18 html=yes show_if=always text="Second block completed, you can take a short break. <br /><br />Press space when you are ready to continue<br />" x=0 y=0 z_index=0

define inline_script slimstampen_setup
	set description "Executes Python code"
	___run__
	m = SpacingModel(includeDoubt = False)
	
	countries = loadImages()
	
	facts = []
	for idx, name in enumerate(countries.keys()):
		facts.append(Fact(idx+1, countries[name], name.lower()))
	
	for fact in facts:
		m.add_fact(fact)
	__end__
	___prepare__
	from __future__ import division
	import math
	import pandas as pd
	import os
	import random
	from pathlib import Path
	from collections import namedtuple
	
	Fact = namedtuple("Fact", "fact_id, question, answer")
	Response = namedtuple("Response","fact, start_time, rt, correct, user_answer, doubt, doubt_classificationCNN, block_n, image_set, model_type, experiment_order, mastery")
	#Response = namedtuple("Response","fact, start_time, rt, correct")
	Encounter = namedtuple("Encounter", "activation, time, reaction_time, decay")
	
	# ------ MAKE SURE THIS DIRECTORY CONTAINS ONLY THE REQUIRED IMAGES -----
	images_dir = os.path.join(var.main_dir, "Images\\Country_Outlines\\set_training") # this is always set_training for first block
	
	def loadImages():
	    images = {}
	    image_paths = list(os.listdir(images_dir))
	    random.shuffle(image_paths)
	    for img in image_paths:
	        path = os.path.join(images_dir, img)
	        name = Path(img).stem
	        images[name] = path
	    return images
	
	class SpacingModel(object):
	
	    # Model constants
	    LOOKAHEAD_TIME = 15000
	    FORGET_THRESHOLD = -0.8
	    DEFAULT_ALPHA = 0.3
	    C = 0.25
	    F = 1.0
	    MASTERY_TIME = 480000 # 8 min
	    
	    # Doubt modifiers
	    CONF_CORR = 1
	    CONF_WRNG = 0.9 
	    DOUBT_CORR = 1.1
	    DOUBT_WRNG = 1.1
	
	    def __init__(self, includeDoubt):
	        self.facts = []
	        self.responses = []
	        self.includeDoubt = includeDoubt
	
	    def get_doubt_mod(self, correct, doubt):
	        if not self.includeDoubt:
	            # No doubt modification takes place
	            return 1
	        if not doubt and correct:
	            # Confident and correct answer
	            return self.CONF_CORR
	        elif not doubt and not correct:
	            # Confident and wrong answer
	            return self.CONF_WRNG
	        elif doubt and correct:
	            # Doubtful and correct answer
	            return self.DOUBT_CORR
	        elif doubt and not correct:
	            # Doubtful and wrong answer
	            return self.DOUBT_WRNG
	
	    def add_fact(self, fact):
	        # type: (Fact) -> None
	        """
	        Add a fact to the list of study items.
	        """
	        # Ensure that a fact with this ID does not exist already
	        if next((f for f in self.facts if f.fact_id == fact.fact_id), None):
	            raise RuntimeError(
	                "Error while adding fact: There is already a fact with the same ID: {}. Each fact must have a unique ID".format(fact.fact_id))
	
	        self.facts.append(fact)
	
	
	    def register_response(self, response):
	        # type: (Response) -> None
	        """
	        Register a response.
	        """
	        # Prevent duplicate responses
	        if next((r for r in self.responses if r.start_time == response.start_time), None):
	            raise RuntimeError(
	                "Error while registering response: A response has already been logged at this start_time: {}. Each response must occur at a unique start_time.".format(response.start_time))
	
	        self.responses.append(response)
	
	
	    def get_next_fact(self, current_time):
	        # type: (int) -> (Fact, bool)
	        """
	        Returns a tuple containing the fact that needs to be repeated most urgently and a boolean indicating whether this fact is new (True) or has been presented before (False).
	        If none of the previously studied facts needs to be repeated right now, return a new fact instead.
	        """
	        # Calculate all fact activations in the near future
	        fact_activations = [(f, self.calculate_activation(current_time + self.LOOKAHEAD_TIME, f)) for f in self.facts]
	
	        seen_facts = [(f, a) for (f, a) in fact_activations if a > -float("inf")]
	        not_seen_facts = [(f, a) for (f, a) in fact_activations if a == -float("inf")]
	
	        # Prevent an immediate repetition of the same fact
	        if len(seen_facts) > 2:
	            last_response = self.responses[-1]
	            seen_facts = [(f, a) for (f, a) in seen_facts if f.fact_id != last_response.fact.fact_id]
	
	        # Reinforce the weakest fact with an activation below the threshold
	        seen_facts_below_threshold = [(f, a) for (f, a) in seen_facts if a < self.FORGET_THRESHOLD]
	        if len(not_seen_facts) == 0 or len(seen_facts_below_threshold) > 0:
	            weakest_fact = min(seen_facts, key = lambda t: t[1])
	            return((weakest_fact[0], False))
	
	        # If none of the previously seen facts has an activation below the threshold, return a new fact
	        return((not_seen_facts[0][0], True))
	
	    def get_mastery_of_fact(self, current_time, fact):
	        activation = self.calculate_activation(current_time + self.MASTERY_TIME, fact)
	        if activation > -float("inf") and activation >= self.FORGET_THRESHOLD:
	            return True
	        return False
	
	    def get_mastered_facts(self, current_time):
	        return [f for f in self.facts if self.get_mastery_of_fact(current_time, f)]
	
	    def get_rate_of_forgetting(self, time, fact):
	        # type: (int, Fact) -> float
	        """
	        Return the estimated rate of forgetting of the fact at the specified time
	        """
	        encounters = []
	
	        responses_for_fact = [r for r in self.responses if r.fact.fact_id == fact.fact_id and r.start_time < time]
	        alpha = self.DEFAULT_ALPHA
	
	        # Calculate the activation by running through the sequence of previous responses
	        for response in responses_for_fact:
	            # Determine value of doubt modifier
	            if self.includeDoubt:
	                if response.doubt_classificationCNN == np.nan:
	                    doubt_mod = 1
	                else:
	                    doubt = True
	                    if response.doubt_classificationCNN == "Confident":
	                        doubt = False
	                    doubt_mod = self.get_doubt_mod(response.correct, doubt)
	            else:
	                doubt_mod = 1
	            
	            activation = self.calculate_activation_from_encounters(encounters, response.start_time)
	            encounters.append(Encounter(activation, response.start_time, self.normalise_reaction_time(response), self.DEFAULT_ALPHA))
	            alpha = self.estimate_alpha(encounters, activation, response, alpha)
	
	            # Update decay estimates of previous encounters
	            encounters = [encounter._replace(decay = self.calculate_decay(encounter.activation, alpha, doubt_mod)) for encounter in encounters]
	
	        return(alpha)
	
	
	    def calculate_activation(self, time, fact):
	        # type: (int, Fact) -> float
	        """
	        Calculate the activation of a fact at the given time.
	        """
	
	        # Encounter = namedtuple("Encounter", "activation, time, reaction_time, decay")
	
	        encounters = []
	
	        responses_for_fact = [r for r in self.responses if r.fact.fact_id == fact.fact_id and r.start_time < time]
	        alpha = self.DEFAULT_ALPHA
	
	        # Calculate the activation by running through the sequence of previous responses
	        for response in responses_for_fact:
	            # Determine value of doubt modifier
	            if self.includeDoubt:
	                if response.doubt_classificationCNN == np.nan:
	                    doubt_mod = 1
	                else:
	                    doubt = True
	                    if response.doubt_classificationCNN == "Confident":
	                        doubt = False
	                    doubt_mod = self.get_doubt_mod(response.correct, doubt)
	            else:
	                doubt_mod = 1
	            
	            # Get activation of fact up to previous encounter
	            activation = self.calculate_activation_from_encounters(encounters, response.start_time)
	            
	            # Add current encounter to encounter list
	            encounters.append(Encounter(activation, response.start_time, self.normalise_reaction_time(response), self.DEFAULT_ALPHA))
	            
	            # Estimate new rate of forgetting up to current encounter
	            alpha = self.estimate_alpha(encounters, activation, response, alpha)
	
	            # Update decay estimates of all encounters till now
	            encounters = [encounter._replace(decay = self.calculate_decay(encounter.activation, alpha, doubt_mod)) for encounter in encounters]
	
	        return(self.calculate_activation_from_encounters(encounters, time))
	
	
	    def calculate_decay(self, activation, alpha, doubt_mod):
	        # type: (float, float) -> float
	        """
	        Calculate activation-dependent decay
	        """
	        return self.C * math.exp(activation) + alpha * doubt_mod
	
	
	    def estimate_alpha(self, encounters, activation, response, previous_alpha):
	        # type: ([Encounter], float, Response, float) -> float
	        """
	        Estimate the rate of forgetting parameter (alpha) for an item.
	        """
	        if len(encounters) < 3:
	            return(self.DEFAULT_ALPHA)
	
	        a_fit = previous_alpha
	        reading_time = self.get_reading_time(response.fact.question)
	        estimated_rt = self.estimate_reaction_time_from_activation(activation, reading_time)
	        est_diff = estimated_rt - self.normalise_reaction_time(response)
	
	        if est_diff < 0:
	            # Estimated RT was too short (estimated activation too high), so actual decay was larger
	            a0 = a_fit
	            a1 = a_fit + 0.05
	        
	        else:
	            # Estimated RT was too long (estimated activation too low), so actual decay was smaller
	            a0 = a_fit - 0.05
	            a1 = a_fit
	
	        # Binary search between previous fit and proposed alpha
	        for _ in range(6):
	            # Adjust all decays to use the new alpha
	            a0_diff = a0 - a_fit
	            a1_diff = a1 - a_fit
	            d_a0 = [e._replace(decay = e.decay + a0_diff) for e in encounters]
	            d_a1 = [e._replace(decay = e.decay + a1_diff) for e in encounters]
	
	            # Calculate the reaction times from activation and compare against observed RTs
	            encounter_window = encounters[max(1, len(encounters) - 5):]
	            total_a0_error = self.calculate_predicted_reaction_time_error(encounter_window, d_a0, reading_time)
	            total_a1_error = self.calculate_predicted_reaction_time_error(encounter_window, d_a1, reading_time)
	
	            # Adjust the search area based on the lowest total error
	            ac = (a0 + a1) / 2
	            if total_a0_error < total_a1_error:
	                a1 = ac
	            else:
	                a0 = ac
	        
	        # The new alpha estimate is the average value in the remaining bracket
	        return((a0 + a1) / 2)
	
	
	    def calculate_activation_from_encounters(self, encounters, current_time):
	        # type: ([Encounter], int) -> float
	        included_encounters = [e for e in encounters if e.time < current_time]
	
	        if len(included_encounters) == 0:
	            return(-float("inf"))
	
	        return(math.log(sum([math.pow((current_time - e.time) / 1000, -e.decay) for e in included_encounters])))
	
	
	    def calculate_predicted_reaction_time_error(self, test_set, decay_adjusted_encounters, reading_time):
	        # type: ([Encounter], [Encounter], Fact) -> float
	        """
	        Calculate the summed absolute difference between observed response times and those predicted based on a decay adjustment.
	        """
	        activations = [self.calculate_activation_from_encounters(decay_adjusted_encounters, e.time - 100) for e in test_set]
	        rt = [self.estimate_reaction_time_from_activation(a, reading_time) for a in activations]
	        rt_errors = [abs(e.reaction_time - rt) for (e, rt) in zip(test_set, rt)]
	        return(sum(rt_errors))
	
	
	    def estimate_reaction_time_from_activation(self, activation, reading_time):
	        # type: (float, int) -> float
	        """
	        Calculate an estimated reaction time given a fact's activation and the expected reading time 
	        """
	        return((self.F * math.exp(-activation) + (reading_time / 1000)) * 1000)
	
	
	    def get_max_reaction_time_for_fact(self, fact):
	        # type: (Fact) -> float
	        """
	        Return the highest response time we can reasonably expect for a given fact
	        """
	        reading_time = self.get_reading_time(fact.question)
	        max_rt = 1.5 * self.estimate_reaction_time_from_activation(self.FORGET_THRESHOLD, reading_time)
	        return(max_rt)
	
	
	    def get_reading_time(self, text):
	        # type: (str) -> float
	        """
	        Return expected reading time in milliseconds for a given string
	        """
	        word_count = len(text.split())
	
	        if word_count > 1:
	            character_count = len(text)
	            return(max((-157.9 + character_count * 19.5), 300))
	        
	        return(300)
	
	    
	    def normalise_reaction_time(self, response):
	        # type: (Response) -> float
	        """
	        Cut off extremely long responses to keep the reaction time within reasonable bounds
	        """
	        rt = response.rt if response.correct else 60000
	        max_rt = self.get_max_reaction_time_for_fact(response.fact)
	        return(min(rt, max_rt))
	
	
	    def export_data(self, path = None):
	        # type: (str) -> DataFrame
	        """
	        Save the response data to the specified csv file, and return a copy of the pandas DataFrame.
	        If no path is specified, return a CSV-formatted copy of the data instead.
	        """
	
	        def calc_rof(row):
	            return(self.get_rate_of_forgetting(row["start_time"] + 1, row["fact"]))
	            
	        def calc_mastery(row):
	            # Get Fact object
	            fact = [f for f in self.facts if f.fact_id == row["fact_id"]][0]
	            return self.get_mastery_of_fact(row["start_time"], fact)
	
	        dat_resp = pd.DataFrame(self.responses)
	        dat_facts = pd.DataFrame([r.fact for r in self.responses])
	        dat_facts.drop(columns=["question"], inplace=True)
	        dat = pd.concat([dat_resp, dat_facts], axis = 1)
	
	        # Add column for rate of forgetting estimate after each observation
	        dat["alpha"] = dat.apply(calc_rof, axis = 1)
	        # Add column for mastery after each observation
	        #dat["mastery"] = dat.apply(calc_mastery, axis = 1)
	        dat.drop(columns = "fact", inplace = True)
	
	        # Add trial number column
	        dat.index.name = "trial"
	        dat.index = dat.index + 1
	
	        # Save to CSV file if a path was specified, otherwise return the CSV-formatted output
	        if path is not None:
	            dat.to_csv(path, encoding="UTF-8")
	            return(dat)
	        
	        return(dat.to_csv())
	__end__

define sequence trial_sequence
	set flush_keyboard yes
	set description "Runs a number of items in sequence"
	run present_trial always

define loop while_there_is_time_left
	set source_file ""
	set source table
	set repeat 10000
	set order random
	set description "Repeatedly runs another item"
	set cycles 1
	set continuous no
	set break_if_on_first yes
	set break_if "var.time_up"
	setcycle 0 ignore_this_variable 1
	run trial_sequence

